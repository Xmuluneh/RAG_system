{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Load the data\n",
    "loader = TextLoader('../data/menu_items.csv')\n",
    "documents = loader.load()\n",
    "\n",
    "# Chunk the data\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary /Users/Aaron/.cache/weaviate-embedded did not exist. Downloading binary from https://github.com/weaviate/weaviate/releases/download/v1.23.0/weaviate-v1.23.0-Darwin-all.zip\n",
      "Started /Users/Aaron/.cache/weaviate-embedded: process ID 38009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-01-20T15:57:45+03:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-01-20T15:57:45+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-01-20T15:57:45+03:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-01-20T15:57:45+03:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-01-20T15:57:45+03:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-01-20T15:57:45+03:00\"}\n",
      "{\"action\":\"read_disk_use\",\"level\":\"warning\",\"msg\":\"disk usage currently at 88.42%, threshold set to 80.00%\",\"path\":\"/Users/Aaron/.local/share/weaviate\",\"time\":\"2024-01-20T15:57:45+03:00\"}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m client \u001b[38;5;241m=\u001b[39m weaviate\u001b[38;5;241m.\u001b[39mClient(\n\u001b[1;32m     15\u001b[0m   embedded_options \u001b[38;5;241m=\u001b[39m EmbeddedOptions()\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Populate vector database\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mWeaviate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Define vectorstore as retriever to enable semantic search\u001b[39;00m\n\u001b[1;32m     27\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/rag/lib/python3.12/site-packages/langchain/vectorstores/base.py:417\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    416\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/rag/lib/python3.12/site-packages/langchain/vectorstores/weaviate.py:411\u001b[0m, in \u001b[0;36mWeaviate.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mweaviate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_valid_uuid\n\u001b[1;32m    410\u001b[0m index_name \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLangChain_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muuid4()\u001b[38;5;241m.\u001b[39mhex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 411\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m embedding \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    412\u001b[0m text_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m schema \u001b[38;5;241m=\u001b[39m _default_schema(index_name)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/rag/lib/python3.12/site-packages/langchain/embeddings/openai.py:483\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/rag/lib/python3.12/site-packages/langchain/embeddings/openai.py:367\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    364\u001b[0m     _iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tokens), _chunk_size)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[0;32m--> 367\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     batched_embeddings\u001b[38;5;241m.\u001b[39mextend(r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    374\u001b[0m results: List[List[List[\u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(texts))]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/rag/lib/python3.12/site-packages/langchain/embeddings/openai.py:100\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_with_retry\u001b[39m(embeddings: OpenAIEmbeddings, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     retry_decorator \u001b[38;5;241m=\u001b[39m \u001b[43m_create_retry_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    104\u001b[0m         response \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/rag/lib/python3.12/site-packages/langchain/embeddings/openai.py:47\u001b[0m, in \u001b[0;36m_create_retry_decorator\u001b[0;34m(embeddings)\u001b[0m\n\u001b[1;32m     39\u001b[0m max_seconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Wait 2^x * 1 second between each retry starting with\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# 4 seconds, then up to 10 seconds, then 10 seconds afterwards\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry(\n\u001b[1;32m     43\u001b[0m     reraise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m     stop\u001b[38;5;241m=\u001b[39mstop_after_attempt(embeddings\u001b[38;5;241m.\u001b[39mmax_retries),\n\u001b[1;32m     45\u001b[0m     wait\u001b[38;5;241m=\u001b[39mwait_exponential(multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39mmin_seconds, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mmax_seconds),\n\u001b[1;32m     46\u001b[0m     retry\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m---> 47\u001b[0m         retry_if_exception_type(\u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[38;5;241m.\u001b[39mTimeout)\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;241m|\u001b[39m retry_if_exception_type(openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mAPIError)\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;241m|\u001b[39m retry_if_exception_type(openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mAPIConnectionError)\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;241m|\u001b[39m retry_if_exception_type(openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mRateLimitError)\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;241m|\u001b[39m retry_if_exception_type(openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mServiceUnavailableError)\n\u001b[1;32m     52\u001b[0m     ),\n\u001b[1;32m     53\u001b[0m     before_sleep\u001b[38;5;241m=\u001b[39mbefore_sleep_log(logger, logging\u001b[38;5;241m.\u001b[39mWARNING),\n\u001b[1;32m     54\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'error'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"read_disk_use\",\"level\":\"warning\",\"msg\":\"disk usage currently at 88.42%, threshold set to 80.00%\",\"path\":\"/Users/Aaron/.local/share/weaviate\",\"time\":\"2024-01-20T15:58:16+03:00\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "# Load OpenAI API key from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Setup vector database\n",
    "client = weaviate.Client(\n",
    "  embedded_options = EmbeddedOptions()\n",
    ")\n",
    "\n",
    "# Populate vector database\n",
    "vectorstore = Weaviate.from_documents(\n",
    "    client = client,    \n",
    "    documents = chunks,\n",
    "    embedding = OpenAIEmbeddings(),\n",
    "    by_text = False\n",
    ")\n",
    "\n",
    "# Define vectorstore as retriever to enable semantic search\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(template)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Setup RAG pipeline\u001b[39;00m\n\u001b[1;32m     20\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 21\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mretriever\u001b[49m,  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnablePassthrough()} \n\u001b[1;32m     22\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt \n\u001b[1;32m     23\u001b[0m     \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser() \n\u001b[1;32m     25\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# Define LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Define prompt template\n",
    "template = '''I want you to act as a acting nutritionist for people.\n",
    "In an easy way, explain the basics of {nutritionist}.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Setup RAG pipeline\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
